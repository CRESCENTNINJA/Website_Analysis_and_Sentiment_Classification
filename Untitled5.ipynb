{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OrZQ5pzw3_Pn"
      },
      "outputs": [],
      "source": [
        "#Webtoon_Analysis\n",
        "#Comments_Sentiments Classification\n",
        "#Web_Scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GV8AQT6bFLrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd96OtHgF5H7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline\n",
        "import re\n",
        "\n",
        "# Initialize the Hugging Face summarization model\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Function to determine the genre based on keyword matches\n",
        "def determine_genre(text):\n",
        "    genres = {\n",
        "        \"romance\": [\"love\", \"romantic\", \"relationship\", \"heart\"],\n",
        "        \"action\": [\"fight\", \"battle\", \"war\", \"adventure\"],\n",
        "        \"fantasy\": [\"magic\", \"fantasy\", \"supernatural\", \"dream\"],\n",
        "        \"comedy\": [\"funny\", \"humor\", \"comedy\", \"laugh\"],\n",
        "    }\n",
        "    for genre, keywords in genres.items():\n",
        "        if any(re.search(rf'\\b{k}\\b', text, re.IGNORECASE) for k in keywords):\n",
        "            return genre\n",
        "    return \"Unknown\"\n",
        "\n",
        "# Function to summarize content in chunks\n",
        "def summarize_content(content, max_length=1024):\n",
        "    # Split content into manageable chunks\n",
        "    content_chunks = [content[i:i + max_length] for i in range(0, len(content), max_length)]\n",
        "    summaries = []\n",
        "    for chunk in content_chunks:\n",
        "        if len(chunk.split()) > 50:\n",
        "            summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "            summaries.append(summary)\n",
        "    return ' '.join(summaries)\n",
        "\n",
        "# Function to scrape, summarize, and determine genre from a webpage\n",
        "def scrape_and_analyze(url):\n",
        "    # Step 1: Scrape the webpage\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Step 2: Extract all paragraphs\n",
        "    paragraphs = [p.text for p in soup.find_all('p')]\n",
        "    content = ' '.join(paragraphs)\n",
        "\n",
        "    # Step 3: Summarize the content\n",
        "    summary = summarize_content(content)\n",
        "\n",
        "    # Step 4: Determine the genre based on the content\n",
        "    genre = determine_genre(content)\n",
        "\n",
        "    return summary, genre\n",
        "\n",
        "# Example usage\n",
        "# url = 'https://animemangatoon.com/top-anime-and-k-drama-like-true-beauty/'\n",
        "# summary, genre = scrape_and_analyze(url)\n",
        "urls = ['https://animemangatoon.com/top-anime-and-k-drama-like-true-beauty/', 'https://animemangatoon.com/i-love-yoo-shin-ae-and-yeong-gis-path/', 'https://animemangatoon.com/operation-true-love-su-ae-and-minu/', 'https://animemangatoon.com/operation-true-love-su-ae-and-eunhyeok/', 'https://animemangatoon.com/refund-high-school-the-beginning-of-the-second-year/' ]\n",
        "#You can Add more websites here for your convenience, I have added 5.\n",
        "\n",
        "webtoon_data = []\n",
        "for url in urls:\n",
        "    summary, genre = scrape_and_analyze(url)\n",
        "    dict={}\n",
        "    dict['description']=summary\n",
        "    dict['genre']=genre\n",
        "    webtoon_data.append(dict)\n",
        "\n",
        "\n",
        "#This Code Cell Will take time to execute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "VN7lB68MMRPg"
      },
      "outputs": [],
      "source": [
        "# for dct in webtoon_data:\n",
        "#   print(dct['description'][:100], dct['genre'])\n",
        "\n",
        "#Checking the functionality of above code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10eOMjjdGfzC"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Preparing the data\n",
        "descriptions = [item['description'] for item in webtoon_data]\n",
        "genres = [item['genre'] for item in webtoon_data]\n",
        "\n",
        "print (descriptions)\n",
        "print (genres)\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(descriptions)\n",
        "# print(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8G86bB8JgSL"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, genres, test_size=0.2)\n",
        "\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbgNAo09JqZm"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(y_pred)\n",
        "\n",
        "#Marks The End of Task-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evnsek-E4IAP"
      },
      "outputs": [],
      "source": [
        "comments = [\n",
        "    \"I love this story, it's amazing!\",\n",
        "    \"This is the worst webtoon I've ever read.\",\n",
        "    \"Happy sadd sad sad sad sad\"\n",
        "]\n",
        "\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "comments = [\n",
        "    \"I love this story, it's amazing!\",\n",
        "    \"This is the worst webtoon I've ever read.\",\n",
        "    \"Happy sadd sad sad sad sad\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "for comment in comments:\n",
        "    blob = TextBlob(comment)\n",
        "    sentiment = 'positive' if blob.sentiment.polarity > 0 else 'negative'\n",
        "    print(f\"Comment: {comment}, Sentiment: {sentiment}\")\n",
        "\n",
        "\n",
        "#Task 2 Complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLfh8g0LSlZw",
        "outputId": "99496b88-64a9-49e0-f43e-6611ac9522bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask me anything about Castle Swimmer (type 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key for Gemini\n",
        "gem_api_key = \"Your_Gemini API\"  # Replace with your actual API key\n",
        "genai.configure(api_key=gem_api_key)\n",
        "\n",
        "# Function to scrape relevant content from the webpage\n",
        "def scrape_castle_swimmer():\n",
        "    url = \"https://animemangatoon.com/castle-swimmer-unveiling-new-prophecy/\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract relevant paragraphs for context\n",
        "    paragraphs = [p.text for p in soup.find_all('p')]\n",
        "    content = ' '.join(paragraphs)  # Combine all paragraphs\n",
        "    return content\n",
        "\n",
        "# Function to generate a response using Gemini\n",
        "def get_response_from_gemini(user_query, context):\n",
        "\n",
        "    generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 64,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "\n",
        "    }\n",
        "\n",
        "    model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-pro\",\n",
        "    generation_config=generation_config,\n",
        "    )\n",
        "\n",
        "    chat_session = model.start_chat(history=[])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    system_instruction = (\n",
        "        f\"answer the question {user_query}, based on {context} \"\n",
        "    )\n",
        "\n",
        "    response = model.generate_content(system_instruction)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "\n",
        "# Main chatbot loop\n",
        "if __name__ == \"__main__\":\n",
        "    content = scrape_castle_swimmer()\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"Ask me anything about Castle Swimmer (type 'exit' to quit): \")\n",
        "        if user_query.lower() == 'exit':\n",
        "            break\n",
        "        response = get_response_from_gemini(user_query, content)\n",
        "        print(\"AI:\", response)\n",
        "\n",
        "\n",
        "# Task 3 completed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRKEzBSwTeNk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
